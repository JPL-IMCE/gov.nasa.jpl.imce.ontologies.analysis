#    $HeadURL$
#
#    $LastChangedRevision$
#    $LastChangedDate$
#
#    $LastChangedBy$
#
#    Copyright (c) 2009,2010 California Institute of Technology.
#    All rights reserved.
#

<% require 'json' %>

ARTIFACTS_DIR ?= <%= ARTIFACTS_DIR = ENV['ARTIFACTS_DIR'] || 'artifacts' %>
AUDITS_DIR ?= tests/audits
AUDITS_TREE ?= $(AUDITS_TREE_PATH)
AUDITS_TEST_FILE ?= $(AUDITS_DIR)/run-audits$(XML_SUFFIX)

BACKBONE_PREFIX ?= http://imce.jpl.nasa.gov/backbone
BACKBONE_ABSTRACT ?= Aspect
BACKBONE_CONCRETE ?= Concept Entity ReifiedObjectProperty ReifiedStructuredDataProperty StructuredDatatype
BUNDLES_DIR ?= $(ARTIFACTS_DIR)/bundles
BUNDLE_CLOSURE_STEM ?= export-bundle

CLOSE_BUNDLE ?= $(JRUBY_CMD) $(TOOLS)/tools/close-tbox-bundle
CLOSE_EXPORTED_USER_MODELS_BUNDLE_OPTS ?= --info --no-disjoints
CLOSE_EXPORTED_VOCABULARIES_BUNDLE_OPTS ?= --info --excise '$(BACKBONE_PREFIX)' --backbone_iri '$(BACKBONE_PREFIX)' \
		     --abstract '$(BACKBONE_ABSTRACT)' --concrete '$(BACKBONE_CONCRETE)'
CLOSE_IMPORTED_VOCABULARIES_BUNDLE_OPTS ?= --info --no-disjoints
CURL ?= curl
CURL_OPTS ?= --silent

<% DEBUG = ENV['DEBUG'] %>
DEPENDENCIES_FILE ?= .dependencies

ENTAIL ?= $(JRUBY_CMD) $(TOOLS_DIR)/entail
ENTAIL_OPTS = --info --remove-backbone

EMPTY_IMPORTS_FILE ?= empty-imports.yaml

ENTAILMENTS_DIR ?= $(ARTIFACTS_DIR)/entailments

                                                         # { path_to_scan1 => [ path_to_prune1, path_to_prune2, ... ], path_to_scan2 => [ ... ], ... }
<% EXPORTED_VOCABULARIES = JSON.parse(ENV['EXPORTED_VOCABULARIES'] || { 'europa.jpl.nasa.gov/efse/libraries' => [] }.to_json) %>
EXPORTED_VOCABULARIES_BUNDLE_STEM ?= exported-vocabularies
<% EXPORTED_USER_MODELS = JSON.parse(ENV['EXPORTED_USER_MODELS'] || { 'europa.jpl.nasa.gov' => [ 'europa.jpl.nasa.gov/efse/libraries'  ]}.to_json) %>
EXPORTED_USER_MODELS_BUNDLE_STEM ?= exported-user-models

EXTRACT ?= $(JRUBY_CMD) $(TOOLS_DIR)/extract-ontology
EXTRACT_OPTS ?= --host $(FUSEKI_HOST) --port $(FUSEKI_PORT) --dataset $(FUSEKI_DATASET)

FUSEKI_S_DELETE ?= $(FUSEKI_BIN)/s-delete
FUSEKI_S_GET ?= $(FUSEKI_BIN)/s-get
FUSEKI_S_PUT ?= $(FUSEKI_BIN)/s-put
FUSEKI_ENDPOINT ?= $(FUSEKI_PROTOCOL)//$(FUSEKI_HOST):$(FUSEKI_PORT)

GET_UNSATS ?= $(TOOLS_DIR)/get-unsats
GET_UNSAT_PROPS_OPTS ?= --get-props
GET_UNSAT_PROP_SOURCES_OPTS ?= --get-prop-sources
GET_UNSAT_PROP_TARGETS_OPTS ?= --get-prop-targets
GET_UNSAT_SUPS_OPTS ?= --get-sups
GET_UNSAT_FUNC_PROPS_OPTS ?= --get-func-props
GET_UNSAT_IRIS_OPTS ?= 

GET_UNSAT_ROOTS ?= $(TOOLS_DIR)/get-unsat-roots
GET_UNSAT_ROOTS_OPTS ?= --info

<% IMPORTED_VOCABULARIES = JSON.parse(ENV['IMPORTED_VOCABULARIES'] || { 'imce.jpl.nasa.gov' => ['imce.jpl.nasa.gov/www.omg.org', 'imce.jpl.nasa.gov/vocabulary', 'imce.jpl.nasa.gov/foundation/owl2-mof2'], 'iso.org' => [], 'purl.org' => [] }.to_json) %>
IMPORTED_VOCABULARIES_BUNDLE_STEM ?= imported-vocabularies

IRI_TO_MDID ?= $(TOOLS_DIR)/iri-to-mdid
IRI_TO_MDID_OPTS ?=

JRUBY ?= jruby
JRUBY_CMD ?= $(JRUBY) $(JRUBY_OPTS)
JRUBY_OPTS ?= --headless -J-Xmx16384m -J-Djava.util.logging.config.file=logging.properties

LOAD_REPO ?= $(TOOLS_DIR)/load-jena
LOAD_REPO_OPTS ?= --host $(FUSEKI_HOST) --port $(FUSEKI_PORT) --dataset $(FUSEKI_DATASET)

LOCATION_MAPPING_FILE ?= location-mapping.yaml

MAKE_MAKEFILE ?= $(TOOLS_DIR)/make-makefile

OMG_ORG ?= <%= OMG_ORG = 'www.omg.org' %>
<% OMIT_PATTERNS = JSON.parse(ENV['OMIT_PATTERNS'] || ['-embedding'].to_json) %>
ONTOLOGIES_DIR ?= <%= ONTOLOGIES_DIR = ENV['ONTOLOGIES_DIR'] || ARTIFACTS_DIR + '/ontologies' %>
OWL_SUFFIX = .owl

PROJECT ?= europa

REPORTS_DIR ?= $(ARTIFACTS_DIR)/reports
REPORTS_TREE ?= $(REPORTS_TREE_PATH)
REPORTS_TEST_FILE ?= $(REPORTS_DIR)/run-reports$(ZIP_SUFFIX)
RUBY ?= $(JRUBY)
RUN_AUDITS ?= $(JRUBY_CMD) $(TOOLS_DIR)/run-audits-jena
RUN_AUDITS_OPTS ?= --info --host $(FUSEKI_HOST) --port $(FUSEKI_PORT) --dataset $(FUSEKI_DATASET)
RUN_REPORTS ?= $(RUN_AUDITS)
RUN_REPORTS_OPTS ?= --info --report --host $(FUSEKI_HOST) --port $(FUSEKI_PORT) --dataset $(FUSEKI_DATASET)

SENTINELS_DIR ?= $(ARTIFACTS_DIR)/.sentinels

TESTS_DIR ?= $(ARTIFACTS_DIR)/tests/consistency
TOOLS_DIR ?= $(TOOLS)/tools

UNSATS_REPORT_FILE ?= $(TESTS_DIR)/unsats.csv
UNSAT_PROPS_REPORT_FILE ?= $(TESTS_DIR)/unsat-props.csv
UNSAT_PROP_SOURCES_REPORT_FILE ?= $(TESTS_DIR)/unsat-prop-sources.csv
UNSAT_PROP_TARGETS_REPORT_FILE ?= $(TESTS_DIR)/unsat-prop-targets.csv
UNSAT_SUPS_REPORT_FILE ?= $(TESTS_DIR)/unsat-sups.csv
UNSAT_FUNC_PROPS_REPORT_FILE = $(TESTS_DIR)/unsat-func-props.csv

UNSAT_ROOTS_REPORT_FILE = $(TESTS_DIR)/unsat-roots.csv

VALIDATE_OWL ?= $(JRUBY_CMD) -J-Djava.util.logging.config.file=logging.properties $(TOOLS_DIR)/validate-owl
VALIDATE_OWL_OPTS ?= --info --satisfiability --indicate-status

VALIDATE_ROOTS_TEST_FILE ?= $(TESTS_DIR)/validate-roots$(XML_SUFFIX)
VALIDATE_ROOTS_ID ?= validate-roots

VIEW_STEM ?= imce.jpl.nasa.gov/view/

VOCABULARY_BUNDLE_IRI ?= <%= VOCABULARY_BUNDLE_IRI = 'http://imce.jpl.nasa.gov/discipline/fse/fse-bundle' %>

XML_SUFFIX ?= .xml

ZIP_SUFFIX ?= .zip

tmpfile = $(dir $1).$(notdir $1)

-include $(DEPENDENCIES_FILE)

# 
# load ontology metadata
#

<%

  class OMFGraph
    def initialize(iri, stem, o_dir)
      @iri = iri
      @stem = stem
      @o_dir = o_dir
    end
    def ontology_iri
      @iri
    end
    def entailments_iri(type)
      "#{@iri}/#{type}"
    end
    def ontology_file
      "#{@o_dir}/#{@stem}$(OWL_SUFFIX)"
    end
    def ontology_file_iri
      'file://' + ontology_file
    end
    def entailments_file(type)
      "$(ENTAILMENTS_DIR)/#{@stem}/#{type}$(OWL_SUFFIX)"
    end
    def entailments_file_iri(type)
      'file://' + entailments_file(type)
    end
    def ontology_sentinel
      "$(SENTINELS_DIR)/#{@stem}$(OWL_SUFFIX)"
    end
    def entailments_sentinel(type)
      "$(SENTINELS_DIR)/#{@stem}/#{type}$(OWL_SUFFIX)"
    end
  end
  class OMFOntologyGraph < OMFGraph
    def initialize(iri, stem)
      super(iri, stem, '$(ONTOLOGIES_DIR)')
    end
  end
  class OMFBundleGraph < OMFGraph
    def initialize(stem, project)
      @stem = stem
      @project = project
      super(ontology_iri, stem, '$(BUNDLES_DIR)')
    end
    def ontology_iri
      'http://' + path
    end
    def abbrev
      @stem
    end
    def name
      @stem
    end
    def path
      "imce.jpl.nasa.gov/project/#{@project}/#{@stem}"
    end
    def backbone_iri
      "$(BACKBONE_PREFIX)/#{path}"
    end
    def backbone_abbrev
      @stem + '-backbone'
    end
  end

  require 'rexml/parsers/streamparser'
  require 'rexml/streamlistener'

  class EndOfOntology < EOFError
  end
  
  class OntologyListener
  include REXML::StreamListener
    def tag_start(name, attrs)
      case name
      when 'owl:Ontology'
        @iri = attrs['rdf:about']
	@imports = []
        @in_ontology = (name == 'owl:Ontology')
      when 'owl:imports'
        @imports << attrs['rdf:resource']
      end
    end
    def tag_end(name)
      raise EndOfOntology.new('end of ontology') if name == 'owl:Ontology'
    end
    attr_reader :iri, :imports
  end
  
  require 'fileutils'
  require 'find'
  require 'jgrapht-core-0.9.0.jar'
  require 'rexml/document'
  require 'shellwords'

  java_import 'org.jgrapht.experimental.dag.DirectedAcyclicGraph'
  java_import 'org.jgrapht.graph.DefaultEdge'
  java_import 'org.jgrapht.alg.TransitiveClosure'

  # Constants.
  
  ENTAILMENTS = {
	'ClassEntailments' => %w{ AllSubclass },
	'PropertyEntailments' => %w{ InverseProperty AllSubproperty },
	'IndividualEntailments' => %w{ AllInstance DataPropertyValue ObjectPropertyValue SameAs },
  }

  PATHS = {
  	'exported_vocabularies' => EXPORTED_VOCABULARIES,
	'exported_user_models' => EXPORTED_USER_MODELS,
	'imported_vocabularies' => IMPORTED_VOCABULARIES,
  }
	
  # Traverse ontologies and mine metadata.

  metadata = Hash.new { |h, k| h[k] = Set.new }
  iris_by_group = Hash.new { |h, k| h[k] = Set.new }
  begin
    FileUtils.cd(ONTOLOGIES_DIR) do
      PATHS.each do |group, path_hash|
	path_hash.each do |search_path, prune_list|
	  begin
	    Find.find(search_path) do |fp|
	      warn "path #{fp}" if DEBUG
	      warn "prune list #{prune_list.inspect}" if DEBUG
	      warn "match #{prune_list.include?(fp)}" if DEBUG
	      Find.prune if prune_list.include?(fp)
	      next unless File.file?(fp) && File.basename(fp) =~ /\.owl\z/
	      next if OMIT_PATTERNS.any? { |p| fp =~ Regexp.new(p) }
	      warn "processing #{fp}" if DEBUG
	      File.open(fp) do |f|
	        listener = OntologyListener.new
		parser = REXML::Parsers::StreamParser.new(f, listener)
		begin
		  parser.parse
		rescue EndOfOntology
		end

		iri = listener.iri
		raise "no iri for #{fp}" unless iri
		iris_by_group[group] << iri
                imports = listener.imports

		stem = "#{File.dirname(fp)}/#{File.basename(fp, '.owl')}"
		metadata['nodes'] << { 'iri' => iri, 'stem' => stem }

		imports.each do |imported|
		  metadata['edges'] << { 'importing' => iri, 'imported' => imported }
		end
	      end
	    end
	  rescue Errno::ENOENT
	    raise "no search path #{search_path}"
	  end
	end
      end
    end
  rescue Errno::ENOENT
    raise "no ontologies directory #{ONTOLOGIES_DIR}"
  end

  # Check for empty input.
  
  raise "no input ontologies found" if metadata['nodes'].empty?
  
  # Create graph structures.

  graphs = metadata['nodes'].inject({}) do |m, n|
    m[n['iri']] = OMFOntologyGraph.new(n['iri'], n['stem'])
    m
  end

  # Add graph for exported user models bundle.
  
  exported_user_models_bundle_graph = OMFBundleGraph.new('$(EXPORTED_USER_MODELS_BUNDLE_STEM)', '$(PROJECT)')
  graphs[exported_user_models_bundle_graph.ontology_iri] = exported_user_models_bundle_graph

  # Add graph for exported vocabularies bundle.
  
  exported_vocabularies_bundle_graph = OMFBundleGraph.new('$(EXPORTED_VOCABULARIES_BUNDLE_STEM)', '$(PROJECT)')
  graphs[exported_vocabularies_bundle_graph.ontology_iri] = exported_vocabularies_bundle_graph

  # Add graph for imported vocabularies bundle.
  
  imported_vocabularies_bundle_graph = OMFBundleGraph.new('$(IMPORTED_VOCABULARIES_BUNDLE_STEM)', '$(PROJECT)')
  graphs[imported_vocabularies_bundle_graph.ontology_iri] = imported_vocabularies_bundle_graph

  # Create location mapping.
  
  location_map = graphs.values.inject({}) do |m, g|
    m[g.ontology_iri] = g.ontology_file_iri
    m
  end

  # Add location mappings for entailments.

  ENTAILMENTS.each do |type, data|
    iri = exported_user_models_bundle_graph.entailments_iri(type)
    file_iri = exported_user_models_bundle_graph.entailments_file_iri(type)
    location_map[iri] = file_iri
  end
  
  # Create imports graph. Omit back edges; processing does not rely on acyclicity at present.
  
  imports_graph = metadata['edges'].inject(DirectedAcyclicGraph.new(DefaultEdge)) do |memo, edge|
    importing = graphs[edge['importing']]
    raise "no importing graph for #{edge['importing']}" unless importing
    imported = graphs[edge['imported']]
    raise "no imported graph for #{edge['imported']} (from #{edge['importing']})" unless imported
    memo.addVertex(importing)
    memo.addVertex(imported)
    begin
      memo.addEdge(importing, imported)
    rescue Java::JavaLang::IllegalArgumentException
      warn "back edge omitted"
    end
    memo
  end

  # Create imports relationships for synthesized bundles.

  {
    exported_user_models_bundle_graph => iris_by_group['exported_user_models'],
    exported_vocabularies_bundle_graph => iris_by_group['exported_vocabularies'],
    imported_vocabularies_bundle_graph => iris_by_group['imported_vocabularies'],
  }.each do |graph, iris|
    raise "bad vertex #{graph.inspect}" unless OMFBundleGraph === graph
    imports_graph.addVertex(graph)
    iris.each do |iri|
      g = graphs[iri]
      raise "bad edge target #{g.inspect}" unless OMFGraph === g
      imports_graph.addVertex(g)
      imports_graph.addEdge(graph, g)
    end
  end
  imports_graph.addEdge(exported_user_models_bundle_graph, exported_vocabularies_bundle_graph)
  imports_graph.addEdge(exported_vocabularies_bundle_graph, imported_vocabularies_bundle_graph)
  
  # Form transitive closure of imports_graph.
  
  TransitiveClosure::INSTANCE.closeSimpleDirectedGraph(imports_graph)
												      
  # Create imports map.
									
  imports_map = Hash.new { |h, k| h[k] = Set.new }
  iter = imports_graph.iterator
  while iter.hasNext
    source = iter.next
    raise "bad source #{source.inspect}" unless OMFGraph === source
    imports_map[source] = imports_graph.edgesOf(source).map do |e|
      imports_graph.getEdgeTarget(e)
    end.reject do |target|
      target == source
    end
    bad = imports_map[source].reject { |i| OMFGraph === i }
    raise "bad imports for #{source.ontology_iri}: #{bad.inspect}" unless bad.empty?
  end

  # Create rule for creating synthesized bundles.

  synthesized_bundles_rule = Makefile::Rule.new('synthesized-bundles')
  synthesized_bundles_rule.prereqs += [
    exported_user_models_bundle_graph,
    exported_vocabularies_bundle_graph,
    imported_vocabularies_bundle_graph,
  ].map { |g| g.ontology_file }
  
  # Create rules for creating exported user models bundle closure.
 
  exported_user_models_bundle_file_rule = Makefile::Rule.new(exported_user_models_bundle_graph.ontology_file)
  
  iris = []
  files = []
  imports_map[exported_user_models_bundle_graph].each do |gl|
    iris << gl.ontology_iri
    files << gl.ontology_file
  end
  
  exported_user_models_bundle_file_rule.prereqs += files 
  exported_user_models_bundle_file_rule.cmds << "$(call do_close_tbox,#{exported_user_models_bundle_graph.name}," +
  			           "$(CLOSE_EXPORTED_USER_MODELS_BUNDLE_OPTS),#{exported_user_models_bundle_graph.ontology_iri}," +
                                   "#{exported_user_models_bundle_graph.abbrev},#{exported_user_models_bundle_graph.backbone_iri}," +
				   "#{exported_user_models_bundle_graph.backbone_abbrev},#{iris.join(' ')})"

  # Create rules for creating exported user models bundle closure.
 
  exported_vocabularies_bundle_file_rule = Makefile::Rule.new(exported_vocabularies_bundle_graph.ontology_file)
  
  iris = []
  files = []
  imports_map[exported_vocabularies_bundle_graph].each do |gl|
    iris << gl.ontology_iri
    files << gl.ontology_file
  end
  
  exported_vocabularies_bundle_file_rule.prereqs += files 
  exported_vocabularies_bundle_file_rule.cmds << "$(call do_close_tbox,#{exported_vocabularies_bundle_graph.name}," +
  			           "$(CLOSE_EXPORTED_VOCABULARIES_BUNDLE_OPTS),#{exported_vocabularies_bundle_graph.ontology_iri}," +
                                   "#{exported_vocabularies_bundle_graph.abbrev},#{exported_vocabularies_bundle_graph.backbone_iri}," +
				   "#{exported_vocabularies_bundle_graph.backbone_abbrev},#{iris.join(' ')})"

  # Create rules for creating imported user models bundle closure.
 
  imported_vocabularies_bundle_file_rule = Makefile::Rule.new(imported_vocabularies_bundle_graph.ontology_file)
  
  iris = []
  files = []
  imports_map[imported_vocabularies_bundle_graph].each do |gl|
    iris << gl.ontology_iri
    files << gl.ontology_file
  end
  
  imported_vocabularies_bundle_file_rule.prereqs += files 
  imported_vocabularies_bundle_file_rule.cmds << "$(call do_close_tbox,#{imported_vocabularies_bundle_graph.name}," +
  			           "$(CLOSE_IMPORTED_VOCABULARIES_BUNDLE_OPTS),#{imported_vocabularies_bundle_graph.ontology_iri}," +
                                   "#{imported_vocabularies_bundle_graph.abbrev},#{imported_vocabularies_bundle_graph.backbone_iri}," +
				   "#{imported_vocabularies_bundle_graph.backbone_abbrev},#{iris.join(' ')})"

  # Create rules for validating root ontologies.
 
  validate_roots_test_file_rule = Makefile::Rule.new('$(VALIDATE_ROOTS_TEST_FILE)')
  validate_roots_test_file_rule.prereqs << exported_user_models_bundle_graph.ontology_file
  validate_roots_test_file_rule.cmds << "$(call validate_roots,$(VALIDATE_ROOTS_ID),#{exported_user_models_bundle_graph.ontology_iri})"
  
  # Create rules for calculating entailments. All entailments are created by a single command, so we run that command
  # with the first entailment as the target and make the others depend on that.
  
  entailments_top_rule = Makefile::Rule.new('entailments')
  entailments_rules = [entailments_top_rule]

  # Make first rule.
  
  first_type = ENTAILMENTS.keys.first
  first_target = exported_user_models_bundle_graph.entailments_file(first_type)
  entailments_top_rule.prereqs << first_target
  specs = ENTAILMENTS.inject([]) do |s, e|
    type, data = *e
    s << "--spec #{exported_user_models_bundle_graph.entailments_iri(type)}='#{data.join(' ')}'"
  end.join(' ')
  first_rule = Makefile::Rule.new(first_target)
  first_rule.prereqs << exported_user_models_bundle_graph.ontology_file
  first_rule.cmds << %Q{$(call do_entailments,#{exported_user_models_bundle_graph.ontology_iri},#{specs})}
  entailments_rules << first_rule

  # Make other rules.
  
  ENTAILMENTS.keys.drop(1).each do |type|
    data = ENTAILMENTS[type]
    target = exported_user_models_bundle_graph.entailments_file(type)
    rule = Makefile::Rule.new(target)
    rule.prereqs << first_target
    entailments_top_rule.prereqs << target
    entailments_rules << rule
  end
%>

#
# location mapping file
#
# The location mapping file is a YAML file that maps ontology IRIs to file IRIs. It is used by the OWL
# API for ontology loading and retrieval.
#

.PHONY:	location-mapping

location-mapping: $(LOCATION_MAPPING_FILE)

<%=
  rule = Makefile::Rule.new('$(LOCATION_MAPPING_FILE)')
  rule.prereqs << 'Makefile'
  rule.cmds << "@echo '->' $@"
  rule.cmds << '@ > $@'
  rule.cmds += location_map.to_yaml.each_line.inject([]) { |m, o| m << "@echo '#{o.strip}' >> $@"; m }
  rule
%>

#
# validate-roots
#

define validate_roots
  @echo validate '->' $@
  @mkdir -p $(dir $@)
  @$(VALIDATE_OWL) $(VALIDATE_OWL_OPTS) --id $(1) $(2) > $@
endef

.PHONY: validate-roots

validate-roots:	$(VALIDATE_ROOTS_TEST_FILE)

<%= validate_roots_test_file_rule %>

#
# entailments
#

.PHONY:	entailments

define do_entailments
  @echo entail '->' $@
  @mkdir -p $(dir $@)
  @$(ENTAIL) $(ENTAIL_OPTS) --input-iri $(1) $(2) $^
endef

<%= entailments_rules.map { |r| r.to_s }.join("\n") %>

#
# load-production
#

define do_load
  @echo load $(2) '->' $(1)
  @mkdir -p $(dir $@)
  $(CURL) $(CURL_OPTS) \
    -X PUT \
    -H "Content-Type: application/rdf+xml" \
    -G '$(FUSEKI_ENDPOINT)/$(FUSEKI_DATASET)/data' \
    --data-urlencode graph='$(1)' \
    -T '$(2)' > $(call tmpfile,$@) && mv $(call tmpfile,$@) $@
endef

load-production:	load-ontologies-production

.PHONY: load-ontologies-production

<%=
  rule = Rule.new('load-ontologies-production')
  graph_rules = []
  imports_map.keys.each do |g|
    rule.prereqs << g.ontology_sentinel
    graph_rules << graph_rule = Rule.new(g.ontology_sentinel)
    graph_rule.prereqs << g.ontology_file
    graph_rule.cmds << "$(call do_load,#{g.ontology_iri},#{g.ontology_file})"
  end
  rule.to_s + graph_rules.join
%>

load-production:	load-entailments-production

.PHONY: load-entailments-production

<%=
  rule = Rule.new('load-entailments-production')
  graph_rules = []
  [exported_user_models_bundle_graph].each do |g|
    ENTAILMENTS.keys.each do |type|
      rule.prereqs << g.entailments_sentinel(type)
      graph_rules << graph_rule = Rule.new(g.entailments_sentinel(type))
      graph_rule.prereqs << g.entailments_file(type)
      graph_rule.cmds << "$(call do_load,#{g.entailments_iri(type)},#{g.entailments_file(type)})"
    end
  end
  rule.to_s + graph_rules.join
%>

#
# run-audits
#

.PHONY: run-audits

run-audits:	$(AUDITS_TEST_FILE)

define do_audit
  @echo audit '->' $@
  @mkdir -p $(dir $@)
  @$(RUN_AUDITS) $(RUN_AUDITS_OPTS) $(1) $(2) > $(call tmpfile,$@) && mv $(call tmpfile,$@) $@
endef

<%=
  rule = Rule.new('$(AUDITS_TEST_FILE)')
  iris = iris_by_group['exported_user_models'] + [ exported_user_models_bundle_graph.ontology_iri ]
  rule.prereqs << exported_user_models_bundle_graph.ontology_sentinel
  rule.prereqs += imports_map[exported_user_models_bundle_graph].map { |i| i.ontology_sentinel }
  rule.prereqs += ENTAILMENTS.keys.map { |type| exported_user_models_bundle_graph.entailments_sentinel(type) }
  rule.cmds << "$(call do_audit,--audit-tree $(AUDITS_TREE),#{iris.to_a.join(' ')})"
  rule
%>

#
# run-reports
#

.PHONY: run-reports

run-reports:	$(REPORTS_TEST_FILE)

define do_report
  @echo report '->' $@
  @mkdir -p $(dir $@)
  @$(RUN_REPORTS) $(RUN_REPORTS_OPTS) $(1) $(2) > $(call tmpfile,$@) && mv $(call tmpfile,$@) $@
endef

<%=
  rule = Rule.new('$(REPORTS_TEST_FILE)')
  iris = iris_by_group['exported_user_models'] + [ exported_user_models_bundle_graph.ontology_iri ]
  rule.prereqs << exported_user_models_bundle_graph.ontology_sentinel
  rule.prereqs += imports_map[exported_user_models_bundle_graph].map { |i| i.ontology_sentinel }
  rule.prereqs += ENTAILMENTS.keys.map { |type| exported_user_models_bundle_graph.entailments_sentinel(type) }
  rule.cmds << "$(call do_report,--audit-tree $(REPORTS_TREE),#{iris.to_a.join(' ')})"
  rule
%>

#
# identify-unsats
#

.PHONY: identify-unsats

define do_identify_unsats
  @echo identify-unsats '->' $@
  @$(JRUBY_CMD) $(GET_UNSATS) $(GET_UNSAT_IRIS_OPTS) $< \
  	> $(call tmpfile,$@) && mv $(call tmpfile,$@) $@
endef

identify-unsats: $(UNSATS_REPORT_FILE)

$(UNSATS_REPORT_FILE): $(VALIDATE_ROOTS_TEST_FILE)
	$(call do_identify_unsats)
	
#
# identify-unsat-props
#

.PHONY: identify-unsat-props

define do_identify_unsat_props
  @echo identify-unsat-props '->' $@
  @$(JRUBY_CMD) $(GET_UNSATS) $(GET_UNSAT_PROPS_OPTS) $< \
  	> $(call tmpfile,$@) && mv $(call tmpfile,$@) $@
endef

identify-unsat-props: $(UNSAT_PROPS_REPORT_FILE)

$(UNSAT_PROPS_REPORT_FILE): $(VALIDATE_ROOTS_TEST_FILE)
	$(call do_identify_unsat_props)
	
#
# identify-unsat-prop-sources
#

.PHONY: identify-unsat-prop-sources

define do_identify_unsat_prop_sources
  @echo identify-unsat-prop-sources '->' $@
  @$(JRUBY_CMD) $(GET_UNSATS) $(GET_UNSAT_PROP_SOURCES_OPTS) $< \
  	> $(call tmpfile,$@) && mv $(call tmpfile,$@) $@
endef

identify-unsat-prop-sources: $(UNSAT_PROP_SOURCES_REPORT_FILE)

$(UNSAT_PROP_SOURCES_REPORT_FILE): $(VALIDATE_ROOTS_TEST_FILE)
	$(call do_identify_unsat_prop_sources)
	
#
# identify-unsat-prop-targets
#

.PHONY: identify-unsat-prop-targets

define do_identify_unsat_prop_targets
  @echo identify-unsat-prop-targets '->' $@
  @$(JRUBY_CMD) $(GET_UNSATS) $(GET_UNSAT_PROP_TARGETS_OPTS) $< \
  	> $(call tmpfile,$@) && mv $(call tmpfile,$@) $@
endef

identify-unsat-prop-targets: $(UNSAT_PROP_TARGETS_REPORT_FILE)

$(UNSAT_PROP_TARGETS_REPORT_FILE): $(VALIDATE_ROOTS_TEST_FILE)
	$(call do_identify_unsat_prop_targets)
	
#
# identify-unsat-sups
#

.PHONY: identify-unsat-sups

define do_identify_unsat_sups
  @echo identify-unsat-sups '->' $@
  @$(JRUBY_CMD) $(GET_UNSATS) $(GET_UNSAT_SUPS_OPTS) $< \
  	> $(call tmpfile,$@) && mv $(call tmpfile,$@) $@
endef

identify-unsat-sups: $(UNSAT_SUPS_REPORT_FILE)

$(UNSAT_SUPS_REPORT_FILE): $(VALIDATE_ROOTS_TEST_FILE)
	$(call do_identify_unsat_sups)
	
#
# identify-unsat-roots
#

.PHONY: identify-unsat-roots

define do_identify_unsat_roots
  @echo identify-unsat-roots '->' $@
  @$(JRUBY_CMD) $(GET_UNSAT_ROOTS) $(GET_UNSAT_ROOTS_OPTS) $< \
  	> $(call tmpfile,$@) && mv $(call tmpfile,$@) $@
endef

identify-unsat-roots: $(UNSAT_ROOTS_REPORT_FILE)

$(UNSAT_ROOTS_REPORT_FILE): $(VALIDATE_ROOTS_TEST_FILE)
	$(call do_identify_unsat_roots)
	
#
# identify-unsat-func-props
#

.PHONY: identify-unsat-func-props

define do_identify_unsat_func_props
  @echo identify-unsat-func-props '->' $@
  @$(JRUBY_CMD) $(GET_UNSATS) $(GET_UNSAT_FUNC_PROPS_OPTS) $< \
  	> $(call tmpfile,$@) && mv $(call tmpfile,$@) $@
endef

identify-unsat-func-props: $(UNSAT_FUNC_PROPS_REPORT_FILE)

$(UNSAT_FUNC_PROPS_REPORT_FILE): $(VALIDATE_ROOTS_TEST_FILE)
	$(call do_identify_unsat_func_props)
	
#
# synthesized-bundles
#

.PHONY: synthesized-bundles

<%= synthesized_bundles_rule %>

define do_close_tbox
  @echo closure artifact '->' $@
  @mkdir -p $(dir $@)
  $(CLOSE_BUNDLE) $(2) \
    --name $(1) --uri $(3) \
    --namespace '$(4)=>$(3)' \
    --namespace '$(6)=>$(5)' \
    $(7) \
    > $(call tmpfile,$@) && mv $(call tmpfile,$@) $@
endef

<%= exported_user_models_bundle_file_rule %>

<%= exported_vocabularies_bundle_file_rule %>

<%= imported_vocabularies_bundle_file_rule %>

#
# Makefile
#

Makefile: Makefile.erb
	@make -f Makefile.bootstrap $@ ONTOLOGIES_DIR="<%= ENV['ONTOLOGIES_DIR'] %>"

#
# clean
#

.PHONY: clean

clean:
	@rm -rf $(ARTIFACTS_DIR) $(LOCATION_MAPPING_FILE) $(TESTS_DIR) $(AUDITS_DIR)
